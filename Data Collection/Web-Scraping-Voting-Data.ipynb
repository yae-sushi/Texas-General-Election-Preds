{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f489b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and set API url\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# set base url and get homepage html\n",
    "res = requests.get('https://www.sos.state.tx.us/elections/historical/counties.shtml')\n",
    "url = 'https://www.sos.state.tx.us/elections/historical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e752b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check good request\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape county link objects\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "abc = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "counties = soup.find_all('a', {'href': lambda x: x and x.endswith('.shtml')})\n",
    "counties = counties[26:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768c37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of relative urls for each county\n",
    "links = []\n",
    "for i, county in enumerate(counties):\n",
    "    links.append(counties[i].attrs['href'])\n",
    "\n",
    "# get only unique values\n",
    "links = list(set(links))\n",
    "# put in alphabetical order so debugging is easier\n",
    "links = sorted(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74f0a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anderson done!\n",
      "andrews done!\n",
      "angelina done!\n",
      "aransas done!\n",
      "archer done!\n",
      "armstrong done!\n",
      "atascosa done!\n",
      "austin done!\n",
      "bailey done!\n",
      "bandera done!\n",
      "bastrop done!\n",
      "baylor done!\n",
      "bee done!\n",
      "bell done!\n",
      "bexar done!\n",
      "blanco done!\n",
      "borden done!\n",
      "bosque done!\n",
      "bowie done!\n",
      "brazoria done!\n",
      "brazos done!\n",
      "brewster done!\n",
      "briscoe done!\n",
      "brooks done!\n",
      "brown done!\n",
      "burleson done!\n",
      "burnet done!\n",
      "caldwell done!\n",
      "calhoun done!\n",
      "callahan done!\n",
      "cameron done!\n",
      "camp done!\n",
      "carson done!\n",
      "cass done!\n",
      "castro done!\n",
      "chambers done!\n",
      "cherokee done!\n",
      "childress done!\n",
      "clay done!\n",
      "cochran done!\n",
      "coke done!\n",
      "coleman done!\n",
      "collin done!\n",
      "collingsworth done!\n",
      "colorado done!\n",
      "comal done!\n",
      "comanche done!\n",
      "concho done!\n",
      "cooke done!\n",
      "coryell done!\n",
      "cottle done!\n",
      "crane done!\n",
      "crockett done!\n",
      "crosby done!\n",
      "culberson done!\n",
      "dallam done!\n",
      "dallas done!\n",
      "dawson done!\n",
      "deafsmith done!\n",
      "delta done!\n",
      "denton done!\n",
      "dewitt done!\n",
      "dickens done!\n",
      "dimmit done!\n",
      "donley done!\n",
      "duval done!\n",
      "eastland done!\n",
      "ector done!\n",
      "edwards done!\n",
      "ellis done!\n",
      "elpaso done!\n",
      "erath done!\n",
      "falls done!\n",
      "fannin done!\n",
      "fayette done!\n",
      "fisher done!\n",
      "floyd done!\n",
      "foard done!\n",
      "fortbend done!\n",
      "franklin done!\n",
      "freestone done!\n",
      "frio done!\n",
      "gaines done!\n",
      "galveston done!\n",
      "garza done!\n",
      "gillespie done!\n",
      "glasscock done!\n",
      "goliad done!\n",
      "gonzales done!\n",
      "gray done!\n",
      "grayson done!\n",
      "gregg done!\n",
      "grimes done!\n",
      "guadalupe done!\n",
      "hale done!\n",
      "hall done!\n",
      "hamilton done!\n",
      "hansford done!\n",
      "hardeman done!\n",
      "hardin done!\n",
      "harris done!\n",
      "harrison done!\n",
      "hartley done!\n",
      "haskell done!\n",
      "hays done!\n",
      "hemphill done!\n",
      "henderson done!\n",
      "hidalgo done!\n",
      "hill done!\n",
      "hockley done!\n",
      "hood done!\n",
      "hopkins done!\n",
      "houston done!\n",
      "howard done!\n",
      "hudspeth done!\n",
      "hunt done!\n",
      "hutchinson done!\n",
      "irion done!\n",
      "jack done!\n",
      "jackson done!\n",
      "jasper done!\n",
      "jeffdavis done!\n",
      "jefferson done!\n",
      "jimhogg done!\n",
      "jimwells done!\n",
      "johnson done!\n",
      "jones done!\n",
      "karnes done!\n",
      "kaufman done!\n",
      "kendall done!\n",
      "kenedy done!\n",
      "kent done!\n",
      "kerr done!\n",
      "kimble done!\n",
      "king done!\n",
      "kinney done!\n",
      "kleberg done!\n",
      "knox done!\n",
      "lamar done!\n",
      "lamb done!\n",
      "lampasas done!\n",
      "lasalle done!\n",
      "lavaca done!\n",
      "lee done!\n",
      "leon done!\n",
      "liberty done!\n",
      "limestone done!\n",
      "lipscomb done!\n",
      "liveoak done!\n",
      "llano done!\n",
      "loving done!\n",
      "lubbock done!\n",
      "lynn done!\n",
      "madison done!\n",
      "marion done!\n",
      "martin done!\n",
      "mason done!\n",
      "matagorda done!\n",
      "maverick done!\n",
      "mcculloch done!\n",
      "mclennan done!\n",
      "mcmullen done!\n",
      "medina done!\n",
      "menard done!\n",
      "midland done!\n",
      "milam done!\n",
      "mills done!\n",
      "mitchell done!\n",
      "montague done!\n",
      "montgomery done!\n",
      "moore done!\n",
      "morris done!\n",
      "motley done!\n",
      "nacogdoches done!\n",
      "navarro done!\n",
      "newton done!\n",
      "nolan done!\n",
      "nueces done!\n",
      "ochiltree done!\n",
      "oldham done!\n",
      "orange done!\n",
      "palopinto done!\n",
      "panola done!\n",
      "parker done!\n",
      "parmer done!\n",
      "pecos done!\n",
      "polk done!\n",
      "potter done!\n",
      "presidio done!\n",
      "rains done!\n",
      "randall done!\n",
      "reagan done!\n",
      "real done!\n",
      "redriver done!\n",
      "reeves done!\n",
      "refugio done!\n",
      "roberts done!\n",
      "robertson done!\n",
      "rockwall done!\n",
      "runnels done!\n",
      "rusk done!\n",
      "sabine done!\n",
      "sanaugustine done!\n",
      "sanjacinto done!\n",
      "sanpatricio done!\n",
      "sansaba done!\n",
      "schleicher done!\n",
      "scurry done!\n",
      "shackelford done!\n",
      "shelby done!\n",
      "sherman done!\n",
      "smith done!\n",
      "somervell done!\n",
      "starr done!\n",
      "stephens done!\n",
      "sterling done!\n",
      "stonewall done!\n",
      "sutton done!\n",
      "swisher done!\n",
      "tarrant done!\n",
      "taylor done!\n",
      "terrell done!\n",
      "terry done!\n",
      "throckmorton done!\n",
      "titus done!\n",
      "tomgreen done!\n",
      "travis done!\n",
      "trinity done!\n",
      "tyler done!\n",
      "upshur done!\n",
      "upton done!\n",
      "uvalde done!\n",
      "valverde done!\n",
      "vanzandt done!\n",
      "victoria done!\n",
      "walker done!\n",
      "waller done!\n",
      "ward done!\n",
      "washington done!\n",
      "webb done!\n",
      "wharton done!\n",
      "wheeler done!\n",
      "wichita done!\n",
      "wilbarger done!\n",
      "willacy done!\n",
      "williamson done!\n",
      "wilson done!\n",
      "winkler done!\n",
      "wise done!\n",
      "wood done!\n",
      "yoakum done!\n",
      "young done!\n",
      "zapata done!\n",
      "zavala done!\n"
     ]
    }
   ],
   "source": [
    "# for each county link in our \"links\" list, create a dataframe off of the table\n",
    "for link in links:\n",
    "    # reset bool\n",
    "    scraped_last = False\n",
    "    \n",
    "    # isolate county name\n",
    "    county_name = link.split('.')[0]\n",
    "    \n",
    "    # initialize data\n",
    "    data = []\n",
    "    \n",
    "    # request data\n",
    "    res = requests.get(url+link)\n",
    "    \n",
    "    # print in case request doesn't work\n",
    "    if res.status_code != 200:\n",
    "        print('BAD REQUEST')\n",
    "     \n",
    "    # get content from page\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    \n",
    "    # isolate table html\n",
    "    sub_soup = soup.find('table')\n",
    "    \n",
    "    # get all the rows of the table\n",
    "    rows = sub_soup.find_all('tr')\n",
    "    \n",
    "    # iterate through rows in the table\n",
    "    for i, row in enumerate(rows):\n",
    "        # initialize empty dictionary\n",
    "        table = {}\n",
    "        # grab just the text (not tags) from each value in the row\n",
    "        row_data = [value.text for value in rows[i].find_all(['th', 'td'])]\n",
    "        # as long as there is actual values in the row_data, put the values in a dict\n",
    "        if row_data != []:\n",
    "            table['Year'] = row_data[0]\n",
    "            if table['Year'] == '2020':\n",
    "                scraped_last = True # if we capture 2020, set this to True to skip the if statement below\n",
    "            table['Reg Voters'] = row_data[1]\n",
    "            table['Voted'] = row_data[2]\n",
    "            table['Voted %'] = row_data[3]\n",
    "            table['Early Vote'] = row_data[4]\n",
    "            table['EV %'] = row_data[5]\n",
    "            # append this dictionary to data\n",
    "            data.append(table)\n",
    "\n",
    "    \n",
    "    # 2020 does not have a 'tr' wrapper - have to grab it manually \n",
    "    # if we already scraped it in the for loop above this will not run\n",
    "    if scraped_last == False:\n",
    "        # get last 5 values\n",
    "        last_year = sub_soup.find_all('td', {'class': 'align-c'})[-5:]\n",
    "        # repeat process in the for loop\n",
    "        last_year_data = [value.text for value in last_year]\n",
    "        table = {}\n",
    "        table['Year'] = 2020\n",
    "        table['Reg Voters'] = last_year_data[0]\n",
    "        table['Voted'] = last_year_data[1]\n",
    "        table['Voted %'] = last_year_data[2]\n",
    "        table['Early Vote'] = last_year_data[3]\n",
    "        table['EV %'] = last_year_data[4]\n",
    "        # append this dictionary to data\n",
    "        data.append(table)\n",
    "    # make dataframe and drop the first column which is a duplicate of our headers\n",
    "    df = pd.DataFrame(data).drop(0)\n",
    "    # add column to capture county\n",
    "    df['county'] = county_name\n",
    "    # save csv in data folder\n",
    "    df.to_csv(f'voting_data/{county_name}.csv', index=False)\n",
    "    # print county name to track progress\n",
    "    print(f'{county_name} done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417a0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from stack overflow \n",
    "# https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "import glob\n",
    "import os\n",
    "path = 'voting_data/'                    \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "008961ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4311 entries, 0 to 4310\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Year        4311 non-null   int64 \n",
      " 1   Reg Voters  4311 non-null   object\n",
      " 2   Voted       4311 non-null   object\n",
      " 3   Voted %     4311 non-null   object\n",
      " 4   Early Vote  4310 non-null   object\n",
      " 5   EV %        4311 non-null   object\n",
      " 6   county      4311 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 235.9+ KB\n"
     ]
    }
   ],
   "source": [
    "concatenated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88fe9e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "select_years = concatenated_df[(concatenated_df['Year'] == 2012) | \\\n",
    "                               (concatenated_df['Year'] == 2016) | \\\n",
    "                               (concatenated_df['Year'] == 2020)].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1d2dcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeburns/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "/Users/chloeburns/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# restructure dataframe\n",
    "voting_2012 = select_years[select_years['Year'] == 2012]\n",
    "voting_2016 = select_years[select_years['Year'] == 2016]\n",
    "voting_2020 = select_years[select_years['Year'] == 2020]\n",
    "\n",
    "voting_2012.rename(columns = {'Year'      :'year', \n",
    "                              'Reg Voters':'2012_reg_voters', \n",
    "                              'Voted'     :'2012_voted_num', \n",
    "                              'Voted %'   :'2012_voted_perc', \n",
    "                              'Early Vote':'2012_early_vote_num', \n",
    "                              'EV %'      :'2012_early_vote_perc', \n",
    "                              'county'    :'county'}, \n",
    "                   inplace=True)\n",
    "\n",
    "voting_2016.rename(columns = {'Year'      :'year', \n",
    "                              'Reg Voters':'2016_reg_voters', \n",
    "                              'Voted'     :'2016_voted_num', \n",
    "                              'Voted %'   :'2016_voted_perc', \n",
    "                              'Early Vote':'2016_early_vote_num', \n",
    "                              'EV %'      :'2016_early_vote_perc', \n",
    "                              'county'    :'county'}, \n",
    "                   inplace=True)\n",
    "\n",
    "voting_2020.rename(columns = {'Year'      :'year', \n",
    "                              'Reg Voters':'2020_reg_voters', \n",
    "                              'Voted'     :'2020_voted_num', \n",
    "                              'Voted %'   :'2020_voted_perc', \n",
    "                              'Early Vote':'2020_early_vote_num', \n",
    "                              'EV %'      :'2020_early_vote_perc', \n",
    "                              'county'    :'county'}, \n",
    "                   inplace=True)\n",
    "\n",
    "# drop year\n",
    "voting_2012.drop(columns = ['year'], inplace = True)\n",
    "voting_2016.drop(columns = ['year'], inplace = True)\n",
    "voting_2020.drop(columns = ['year'], inplace = True)\n",
    "\n",
    "# merge\n",
    "voting_2012_2016 = voting_2012.merge(voting_2016, how = 'left', on= 'county')\n",
    "voting_numbers = voting_2012_2016.merge(voting_2020, how = 'left', on = 'county')\n",
    "\n",
    "# reorder columns\n",
    "cols = voting_numbers.columns.to_list()\n",
    "cols.remove('county')\n",
    "cols.insert(0, 'county')\n",
    "voting_numbers = voting_numbers[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57fbf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_numbers['county'] = voting_numbers['county'].replace({\n",
    "    'deafsmith': 'deaf smith',\n",
    "    'elpaso'      : 'el paso',\n",
    "    'fortbend'    : 'fort bend',\n",
    "    'jeffdavis'   : 'jeff davis',\n",
    "    'jimhogg'     : 'jim hogg',\n",
    "    'jimwells'    : 'jim wells',\n",
    "    'lasalle'     : 'la salle',\n",
    "    'liveoak'     : 'live oak',\n",
    "    'palopinto'   : 'palo pinto',\n",
    "    'redriver'    : 'red river',\n",
    "    'sanaugustine': 'san augustine',\n",
    "    'sanjacinto'  : 'san jacinto',\n",
    "    'sanpatricio' : 'san patricio',\n",
    "    'sansaba'     : 'san saba',\n",
    "    'tomgreen'    : 'tom green',\n",
    "    'valverde'    : 'val verde',\n",
    "    'vanzandt'    : 'van zandt'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15a266d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add word \"county\" to each county\n",
    "voting_numbers['county'] = [x + ' county' for x in voting_numbers['county']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574d375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_numbers = voting_numbers.sort_values(by = 'county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05f80d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_numbers.to_csv('Data/voting_numbers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
